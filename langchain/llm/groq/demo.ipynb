{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-03T02:13:18.971472Z",
     "start_time": "2024-07-03T02:13:18.959186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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 https://groq-api.923828.xyz/v1\n"
     ]
    }
   ],
   "source": [
    "# åŸºç¡€ä»£ç å¼•å…¥\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# åŠ è½½å½“å‰ç›®å½•ä¸‹çš„.envæ–‡ä»¶\n",
    "# load_dotenv()\n",
    "# load_dotenv(override=True) ä¼šé‡æ–°è¯»å–.env\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# ç°åœ¨å¯ä»¥åƒè®¿é—®æ™®é€šç¯å¢ƒå˜é‡ä¸€æ ·è®¿é—®.envæ–‡ä»¶ä¸­çš„å˜é‡äº†\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "groq_api_base = os.getenv('GROQ_API_BASE')\n",
    "\n",
    "print(groq_api_key, groq_api_base)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "# llama3-70b-8192\n",
    "# llama3-8b-8192\n",
    "# mixtral-8x7b-32768\n",
    "# gemma-7b-it\n",
    "# whisper-large-v3\n",
    "# qwen å…¼å®¹ openaiçš„æ¥å£\n",
    "groq_llm_openai = ChatOpenAI(\n",
    "    openai_api_base=groq_api_base,\n",
    "    openai_api_key=groq_api_key,\n",
    "    model_name=\"llama3-8b-8192\",\n",
    "    temperature=0.7,\n",
    "    streaming=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T02:13:22.825217Z",
     "start_time": "2024-07-03T02:13:22.787790Z"
    }
   },
   "id": "1ea8707e43fd4abb",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "AIMessage(content=\"ğŸ˜Š I'm LLaMA, an AI assistant developed by Meta AI that can understand and respond to human input in a conversational manner. I'm not a human, but a computer program designed to simulate conversation, answer questions, and even generate text based on the input I receive.\\n\\nI'm here to help you with any questions or topics you'd like to discuss. I can provide information on a wide range of subjects, from science and history to entertainment and culture. I can also help with language-related tasks, such as language translation, grammar correction, and text summarization.\\n\\nSo, what's on your mind? What would you like to talk about? ğŸ¤”\", response_metadata={'finish_reason': 'stop'}, id='run-5a2676cc-b310-4690-a929-4470c6b5f874-0')"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_llm_openai.invoke(\"ä½ æ˜¯è°å‘€ï¼Ÿ\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T03:23:35.253547Z",
     "start_time": "2024-07-03T03:23:32.302330Z"
    }
   },
   "id": "f1b0b183d21414c2",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2efc9429eefddc84"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
