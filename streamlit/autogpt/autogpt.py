from langchain.prompts import PromptTemplate
from langchain.chains.llm import LLMChain  # , SequentialChain
from langchain.chains.sequential import SequentialChain
import streamlit as st
from langchain_core.runnables import RunnablePassthrough
# åŸºæœ¬é…ç½®
from langchain_openai import ChatOpenAI
import os
from dotenv import load_dotenv

load_dotenv(override=True)

qw_llm_openai = ChatOpenAI(
    openai_api_base=os.getenv('DASHSCOPE_API_BASE'),
    openai_api_key=os.getenv('DASHSCOPE_API_KEY'),
    model_name="qwen2-1.5b-instruct",
    temperature=0,
)

st.title('AutoGPT Wizard')
prompt = st.text_input('Tell me a topic you want to learn its programming language:')

# Prompt templates
language_template = PromptTemplate(
    input_variables=['topic'],
    template='Suggest me a programming language for {topic} and respond in a code block with the language name only'
)

book_recommendation_template = PromptTemplate(
    input_variables=['programming_language'],
    template='''Recommend me a book based on this programming language {programming_language}

    The book name should be in a code block and the book name should be the only text in the code block
    '''
)

# llm = OpenAI(temperature=0.9, model_name="gpt-3.5-turbo")
language_chain = LLMChain(llm=qw_llm_openai, prompt=language_template, verbose=True, output_key='programming_language')
# åœ¨æ–°çš„ç®¡é“æ–¹å¼ä¸­ï¼Œverbose=True å‚æ•°å¯èƒ½ä¸å†é€‚ç”¨ã€‚
# å¯¹äº output_key='programming_language' ï¼Œåœ¨æ–°çš„å®ç°æ–¹å¼ä¸­å¯èƒ½ä¸éœ€è¦ä»¥è¿™ç§æ–¹å¼æŒ‡å®šè¾“å‡ºé”®ã€‚å…·ä½“å–å†³äºæ‚¨åç»­å¦‚ä½•å¤„ç†ç”Ÿæˆçš„ç»“æœ
# language_chain = RunnablePassthrough() | language_template | qw_llm_openai

book_recommendation_chain = LLMChain(llm=qw_llm_openai, prompt=book_recommendation_template,
                                     verbose=True, output_key='book_name')

# book_recommendation_chain = RunnablePassthrough() | book_recommendation_template | qw_llm_openai

# auto-gpt æ€ä¹ˆæ„Ÿè§‰åƒmult chain å‘¢ ğŸ¤”

sequential_chain = SequentialChain(
    chains=[language_chain, book_recommendation_chain],
    input_variables=['topic'],
    output_variables=['programming_language', 'book_name'],
    verbose=True)

if prompt:
    reply = sequential_chain.invoke({'topic': prompt})

    with st.expander("Result"):
        st.info(reply)

    with st.expander("Programming Language"):
        st.info(reply['programming_language'])

    with st.expander("Recommended Book"):
        st.info(reply['book_name'])
